{"pages":[],"posts":[{"title":"Open Source Routing Machine (OSRM) with Python","text":"OSRM 최적의 경로 찾기Open Source Routing Machine (OSRM)은 지도상의 도로 Network에서 최단 경로를 계산하는 C ++ 라우팅 엔진입니다. 지도상의 포인트 A와 포인트 B 사이의 거리를 구하는 가장 쉬운 방법은 직선거리를 계산하는 것입니다. 그러나 직선거리로 계산하게되면 도로 상황을 무시해서 실제 이동거리와 많은 차이가 발생할 수 있는데, 이 OSRM API를 활용하면 네이버 길찾기처럼 경로, 소요시간, 이동거리 등과 같은 값을 얻을 수 있어서 유용합니다. API DocumentAPI Document를 보면 Nearest, Route, Trip등 다양한 Service가 있는데, 이 중에서 Route service를 활용해보려고 합니다. 신도림역 -&gt; 문래역 Route 이동수단도 선택이 가능한데 아래에서는 bike로 설정 car, bike, foot route는 map에서 그리기 용이한 형태로 저장 1234567891011121314151617181920212223242526272829303132import requestsimport foliumimport polylineimport jsonimport pandas as pddef get_route(origin_lon, origin_lat, dest_lon, dest_lat): &quot;&quot;&quot;출발지, 도착지 좌표를 입력해서 Route 정보 Return&quot;&quot;&quot; loc = &quot;{},{};{},{}&quot;.format(origin_lon, origin_lat, dest_lon, dest_lat) url = &quot;http://router.project-osrm.org/route/v1/bike/&quot; r = requests.get(url + loc) if r.status_code!= 200: return {} res = r.json() routes = polyline.decode(res['routes'][0]['geometry']) start_point = [res['waypoints'][0]['location'][1], res['waypoints'][0]['location'][0]] end_point = [res['waypoints'][1]['location'][1], res['waypoints'][1]['location'][0]] distance = res['routes'][0]['distance'] route = {'route':routes, 'start_point':start_point, 'end_point':end_point, 'distance':distance } return routeorigin_lon, origin_lat, dest_lon, dest_lat = 126.890975,37.508767,126.89472929779438, 37.51792066883597test_route = get_route(pickup_lon, pickup_lat, dropoff_lon, dropoff_lat) print(test_route)12345678910111213{'route': [(37.50901, 126.89072), (37.50918, 126.89083), (37.50932, 126.89135), (37.50992, 126.89262), (37.51094, 126.89181), (37.51198, 126.89393), (37.51315, 126.89728), (37.51476, 126.89392), (37.51491, 126.89407), (37.51792, 126.89477)], 'start_point': [37.50901, 126.890723], 'end_point': [37.517916, 126.894771], 'distance': 1584.2} 123456789101112131415161718192021222324def get_map(route): &quot;&quot;&quot;출발지, 도착지, route 정보를 folium map에 표시&quot;&quot;&quot; route_map = folium.Map(location=[(route['start_point'][0] + route['end_point'][0])/2, (route['start_point'][1] + route['end_point'][1])/2], zoom_start=13) folium.PolyLine( route['route'], weight=8, color='blue', opacity=0.6 ).add_to(route_map) folium.Marker( location=route['start_point'], icon=folium.Icon(icon='play', color='green') ).add_to(route_map) folium.Marker( location=route['end_point'], icon=folium.Icon(icon='stop', color='red') ).add_to(route_map) return route_map Route 시각화신도림역 -&gt; 문래역 Route가 map에 잘 표현된 걸 확인할 수 있습니다.","link":"/2021/01/24/Open-Source-Routing-Machine-OSRM-with-Python/"},{"title":"User action 연속일수 구하기","text":"학생 연속 출석일수 구하기제가 학생 3명이 있는 학급을 관리하고 있는 선생님이라고 가정해보겠습니다. 출석을 열심히 한 학생에게 상을 주고 싶은데, 특정 기간동안 많이 출석한 학생보다 연속적으로 오래 출석한 학생에게 상을 주고 싶습니다. 아래 데이터는 학생 3명의 2020-12-01 ~ 2020-12-05 5일간의 출석기록입니다.DB에 아래 데이터가 있다고 가정하고 SQL을 이용해서 학생별로 연속출석일수를 구해보겠습니다. Table: Student student_code date status A 2020-12-01 1 A 2020-12-02 0 A 2020-12-03 1 A 2020-12-04 0 A 2020-12-05 1 B 2020-12-01 1 B 2020-12-02 1 B 2020-12-03 1 B 2020-12-04 0 B 2002-12-05 0 C 2020-12-01 1 C 2020-12-02 1 C 2020-12-03 0 C 2020-12-04 1 C 2020-12-05 1 12345678910111213141516171819202122232425262728with student_attendance as ( SELECT student_code , date , status , row_number() over(partition by student_code order by date) s_rownum , row_number() over(partition by student_code, status order by date) s_t_rownum FROM student), student_consecutive_days as ( SELECT student_code , date , status , (rn1 - rn2) as grp , min(date) as start_date , max(date) as end_date , count(*) as consecutive_days FROM student_attendance GROUP BY student_code, status, grp ORDER BY student_code, start_date)SELECT student_code , max(consecutive_days) # 가장 길었던 연속일수FROM student_consecutive_daysWHERE status = 1 # 출석했던 구간 중GROUP BY student_code SQL 설명student_attendance 라는 가상 table을 만듭니다. 기존 data에서 출석여부별 연속기간을 구하기 위해 row nuber를 붙이는데여기서 student_code를 partition으로 하는 row number와 (student_code, status) 를 partition을 하는 row number 두개가 필요합니다. Why? 첫 번째 row number는 학생마다 날짜순서대로 붙게됩니다. 두 번째 row number는 status가 추가적으로 partiton 되어있기 때문에학생의 날짜, 출석여부 별로 row number가 붙게됩니다. 즉, 연속적으로 출석하지 않은 시점에 row number 1과 row number 2의 차이가 발생하게 됩니다. 그러면 이 차이가 똑같은 구간은 똑같은 상태가 지속되고 있음을 나타내게 됩니다. 학생의 출석 상태별 연속되는 구간 Table을 만들고 난 후, 마지막으로 출석상태인 구간만 filtering 하여 max 연속일수를 구하면학생별로 기간 내 가장 길었던 연속일수를 구할 수 있습니다.","link":"/2021/01/30/User-action-%EC%97%B0%EC%86%8D%EC%9D%BC%EC%88%98-%EA%B5%AC%ED%95%98%EA%B8%B0/"},{"title":"TIL - Pyhton &#39;list&#39; object has no attribute &#39;split&#39;","text":"구글링하면서 임기응변식으로 Python을 사용하고 학습하게 되었을 때 이런 부분들에서 약점이 생기는 것 같습니다. 위 제목의 에러가 발생하게 된 원인은 list에 split 메소드를 사용했기 때문인데, split 메소를 어떻게 써야하는지 document를 보면서 짚고 넘어가려고 합니다. Error Message1'list' object has no attribute 'split' Document 첫 문구에 string의 word를 list형태로 return해준다고 나와있습니다. 즉, list에 직접 split 메소드를 쓸 수 없고 list안에 있는 문자열을 순회하면서 사용하면 됩니다.","link":"/2021/01/09/split/"},{"title":"고객생애가치(Customer Lifetime Value)","text":"고객생애가치 (Customer Lifetime Value)란 ?고객이 과거에 회사의 제품을 구매하거나 서비스 이용료로 지불했던 금액 또는 미래 예상 지불 금액을 기반으로 고객의 가치를 정의하는 것입니다. 즉, 단기적으로만 보지 않고 장기적 관점에서 고객의 가치를 평가하는 지표입니다. 왜 중요할까?회사 입장에서는 모든 고객에게 집중할 수 없습니다. 그렇다면 고객 중에서도 회사 이익에 기여하는 부분이 큰 고객에게 집중하는 것이 비용대비 효율이 좋을 것입니다. 또한, 가치가 낮은 고객이 있다면 어떻게 하면 충성도를 높여서 가치가 높은 고객으로 전환 시킬지에 대한 아이디어도 얻을 수 있을 것입니다. CLV 계산방법원문 과거이력기반 (Historic) 개별 고객이 거래한 과거 구매 총가치 or 총이익의 합계 측정 CLV(Historic) = (거래1 + 거래2 + 거래 3… + 거래 n) * 평균마진 예측기반 (Predictive) 과거이력기반보다 더 많은 데이터를 사용하기 때문에 고객 생애주기 동안 회사에 제공할 총 가치를 나타내는 데 좋은 지표가 될 수 있음 가격, 할인 등의 변동을 고려할 때 정확한 예측을 결정하는 것은 어려울 수 있음 CLV(Predictive) = ((월 평균 거래횟수 * 평균구매금액) * 평균 총마진) * 평균고객수명 고객수명기반 (Lifespan) 고객가치와 고객 수명을 가지고 계산하는 방법 평균구매가치 일정 기간 동안의 총 매출을 같은 기간 동안 발생한 구매 횟수로 나누기 총 매출 / 총 구매 횟수 평균구매빈도 위의 구매 횟수를 해당 기간 동안 구매한 고객수로 나누기 총 구매 횟수 / 총 구매 고객수 평균고객가치 평균구매가치 * 평균구매빈도 평균고객수명 고객들이 계속 구매하는 년 수의 평균값 계산 CLV(Lifespan) = 평균고객가치 * 평균고객수명 동질집단기반 (Cohort) 유사한 특성을 가진 고객을 수집하고 그룹화함 여러 유형의 고객들 사이에서 결론을 도출하는데 유용함 개인화기반 (Individual) 개인화된 CLV는 마케팅의 더 넓은 관점을 고려하는데 유용 이 CLV를 통해 어떤 마케팅 채널이 효율적인지, 누구를 타켓팅 해야하는지 등의 인사이트를 얻을 수 있음 CLV 인사이트원문 마케팅 활동을 통해 유치한 고객은 일반 고객들보다 CLV가 낮다 마케팅 활동에 비용이 들어갔기 때문에 같은 질의 고객이어도 CLV가 낮음 마케팅 활동을 통해 수요가 창출된 고객은 고객 이탈율이 상대적으로 높음 e.g) 사은품으로 유입된 고객 제품 구입 빈도가 CLV에 가장 큰 영향을 끼친다 제품 하나를 더 사게 하는 전략이 비싼 제품을 구입하게 하는 것보다 CLV 증가에 큰 효과가 있음 같은 제품이라도 제품의 포지셔닝에 따라 CLV가 다르다 고객의 의도에 맞게 마케팅을 하면 제품을 바꾸지 않고도 CLV를 바꿀 수 있음","link":"/2021/02/11/customer-lifetime-value/"},{"title":"TIL - Algorithm - adjacent element","text":"알고리즘 지뢰찾기 문제를 풀다가 배운 것문제 출처: codesignal arcade intro 24 처음 접근은 반복문을 통해 현재 위치에서 +1 -1 해가며 주변에 지뢰가 있는지 확인했지만, 별도로 [-1, 0, 1] list를 loop에 넣어서 인근 element를 탐색하는 방법 12for x in [-1, 0, 1]: for y in [-1, 0, 1]:","link":"/2021/03/01/2021-03-01-algorithm-adjacent-element-check/"},{"title":"Python - json.loads()와 json.dumps()의 차이","text":"JSON (JavaScript Object Notation)json object는 key value pair로 이루어지고 { } 중괄호에 의해 둘러쌓여있습니다. json.loads() json.loads()는 문자열을 받아서 json object를 return합니다. json.dumps() json.dumps()는 json object를 받아서 문자열을 return 합니다.","link":"/2021/03/24/2021-03-24-json-load-dump/"},{"title":"카카오 맵 API를 활용한 좌표 &lt;-&gt; 주소 변환","text":"API 활용 준비https://developers.kakao.com 카카오 개발자 페이지에서 여러 카카오 제품의 API를 활용할 수 있는데, 그 중에서 좌표와 주소 변환 관련해서는 지도/로컬 제품을 사용하면 됩니다. REST API 테스트 페이지에서는 어떤 기능을 어떻게 활용할 수 있는지 확인할 수 있습니다. 확인해 볼 기능은 좌표와 주소간 변환이니 아래 이미지의 노란색 2개를 확인해보겠습니다. 주소 -&gt; 좌표 변환123456789101112131415161718192021222324252627import requestsKAKAO_REST_API_KEY = '' # 발급받은 API KEYdef convert_address_to_coordinates(address): &quot;&quot;&quot; 입력받은 주소를 WGS84 좌표계 좌표로 변환 &quot;&quot;&quot; url = 'https://dapi.kakao.com/v2/local/search/address.json?query=' + address header = {'Authorization': 'KakaoAK ' + KAKAO_REST_API_KEY} r = requests.get(url, headers=header) if r.status_code == 200: lng = float(r.json()[&quot;documents&quot;][0][&quot;address&quot;]['x']) lat = float(r.json()[&quot;documents&quot;][0][&quot;address&quot;]['y']) else: return None return lat, lng# Testconvert_address_to_coordinates(&quot;서울특별시 강남구 강남대로 396&quot;) # 강남역 주소 # Output# (37.4981646510326, 127.028307900881) 좌표가 맞는지 지도에 찍어봤는데, 강남역을 가리키고 있습니다. 좌표 -&gt; 주소 변환이번에는 좌표에서 주소로 변환해보겠습니다. 123456789101112131415161718192021222324def convert_coordinates_to_address(lat, lng): &quot;&quot;&quot; 입력받은 위도, 경도를 도로명, 지번 주소로 변환 &quot;&quot;&quot; y, x = str(lat), str(lng) url = 'https://dapi.kakao.com/v2/local/geo/coord2address.json?x={}&amp;y={}'.format(x, y) header = {'Authorization': 'KakaoAK ' + KAKAO_REST_API_KEY} r = requests.get(url, headers=header) if r.status_code == 200: road_address = r.json()[&quot;documents&quot;][0][&quot;road_address&quot;]['address_name'] bunji_address = r.json()[&quot;documents&quot;][0][&quot;address&quot;]['address_name'] else: return None return road_address, bunji_address# TESTconvert_coordinates_to_address(37.4981646510326, 127.028307900881)# Output# ('서울특별시 강남구 강남대로 396', '서울 강남구 역삼동 804') 이전에 강남역 좌표로 얻은 것을 다시 역지오코딩을 했을 때 강남역 주소가 나오는 것을 확인할 수 있습니다.","link":"/2021/02/07/%EC%A3%BC%EC%86%8C%EC%A2%8C%ED%91%9C%EB%B3%80%ED%99%98/"},{"title":"Book - 틀리지 않는 법","text":"Book - 틀리지 않는 법 지금까지 읽었던 Data science 관련 교양서 중 가장 두꺼운 책입니다. (총 페이지가 무려 614p..) 블로그, 커뮤니티에서 추천하는 걸 보고 구매했는데 모든 내용을 다 이해하지는 못했지만 앞으로 업무하면서 충분히 도움이 될 만한 내용들이 많아서 만족했습니다. 책의 어떤 내용들은 읽었을 때에는 당연한 얘기일 수도 있어 보이지만 일을 하다보면 간과하기 쉬운 부분이기도 했습니다. 프롤로그어떤 가정을 품고 있는가? 그 가정은 정당한가?전쟁에서 총알구멍이 아군의 비행기에서 한 대당 두 개 이상 절대 발견되지 않는다면? -&gt; 조종사들이 적의 포화를 피하는 데 뛰어난 것이 아니라 두 번 이상 맞은 비행기는 돌아오지 못했다는 것 선형성같은 계산을 다른 방식으로 여러 차례 반복했을 때, 다른 답이 나온다면 문제가 있다. 비례를 잘못사용해서 해석할 경우 어떤 술집이 문 닫을 시각까지 남아 있던 두 남자 중 한 명이 다른 한명을 폭행 이것이 곧 미국인 50%가 폭행을 당한 격이라고 말할 수 없는 것 Volumn과 Ratio를 문제 상황에 맞게 활용 큰 수의 법칙 이미 벌어진 일에 대해서 균형을 맞추는 것이 아니라, 비율로 따져서 과거의 횟수가 무시해도 좋을 만큼 작아질 때까지 새로운 데이터를 더함으로써 이미 벌어진 일을 희석 추론인간은 패턴이 없는 곳에서도 패턴을 읽어 내고 실제 패턴이 있을 때에는 그 힘을 과대평가하는 경향이 있다.P-value 해킹 저널의 다양한 분야를 조사한 결과, P-value 그래프는 기준인 0.05로 다가갈수록 눈에 띄게 상승 발표 불가능한 실험 결과 중 다수가 저자의 의도로 경계선 너머 허용할 수준으로 넘어왔다는 추론 가능 판사가 아니라 탐정 p-value와 더불어 신뢰 구간 같이 보기 신뢰 구간은 실제 관찰한 결과에 합리적으로 부합하는 가설들의 범위를 말함 신뢰 구간이 [3%, 17%]라면 효과가 양성이긴 하지만 그렇게 까지 크진 않다는 것 But, [9%, 11%]라면 효과가 양성일 뿐 아니라 상당이 크다는 것을 암시 회귀상관관계와 정보량간의 관계 측정 항목들 간의 상관관계가 더 클수록 분류된 데이터의 정보량은 작아짐 즉 Segment할 때에는 상관관계가 적은 변수로 해야 의미가 있음 상관관계가 없다고 해서 연관성이 없는 것이 아니다 골턴의 상관관계 개념은 한 변수가 증가하면 다른 변수도 그에 비례하여 증가하거나 감소하는 선형적 관계만 감지 But, 모든 관계가 선형적 관계는 아님 수학적 도구는 특정 종류희 현상은 감지하지만 다른 종류는 감지하지 못함 상관관계가 없다는 말은 상관 계수가 감지할 수 있는 종류의 관계가 없다는 뜻일 뿐 에필로그기대값 기대값은 우리가 기대하는 값이 아니라, 가능한 결과들에 대한 확률적 타협","link":"/2021/01/17/%ED%8B%80%EB%A6%AC%EC%A7%80%EC%95%8A%EB%8A%94%EB%B2%95/"}],"tags":[{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"GIS","slug":"GIS","link":"/tags/GIS/"},{"name":"OSRM","slug":"OSRM","link":"/tags/OSRM/"},{"name":"SQL","slug":"SQL","link":"/tags/SQL/"},{"name":"TIL","slug":"TIL","link":"/tags/TIL/"},{"name":"LTV","slug":"LTV","link":"/tags/LTV/"},{"name":"CLV","slug":"CLV","link":"/tags/CLV/"},{"name":"마케팅","slug":"마케팅","link":"/tags/%EB%A7%88%EC%BC%80%ED%8C%85/"},{"name":"Algorithm","slug":"Algorithm","link":"/tags/Algorithm/"},{"name":"API","slug":"API","link":"/tags/API/"},{"name":"좌표변환","slug":"좌표변환","link":"/tags/%EC%A2%8C%ED%91%9C%EB%B3%80%ED%99%98/"},{"name":"Book","slug":"Book","link":"/tags/Book/"},{"name":"Data Science","slug":"Data-Science","link":"/tags/Data-Science/"}],"categories":[{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"SQL","slug":"SQL","link":"/categories/SQL/"},{"name":"TIL","slug":"TIL","link":"/categories/TIL/"},{"name":"Data Analysis","slug":"Data-Analysis","link":"/categories/Data-Analysis/"},{"name":"GIS","slug":"Python/GIS","link":"/categories/Python/GIS/"},{"name":"Algorithm","slug":"Algorithm","link":"/categories/Algorithm/"},{"name":"Book","slug":"Book","link":"/categories/Book/"}]}